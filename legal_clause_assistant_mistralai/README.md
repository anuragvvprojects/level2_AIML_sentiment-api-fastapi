# ðŸ§  Legal Clause Assistant (Local RAG using Meta-Llama-Guard-2-8B)

This is a complete Retrieval-Augmented Generation (RAG) project to assist with legal clause understanding, powered by **Meta-Llama-Guard-2-8B** running locally using `transformers` + `bitsandbytes`.

It uses the CUAD dataset to retrieve relevant legal contract segments and generate contextual answers.

---

## ðŸ“‚ Project Structure

```
legal_clause_assistant/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ingest.py                   # Chunk + embed CUAD into Chroma
â”‚   â”œâ”€â”€ retriever.py                # Load vector store & retrieve
â”‚   â”œâ”€â”€ qa_chain.py                 # QA pipeline using OpenAI
â”‚   â”œâ”€â”€ qa_chain_mistral.py         # âœ… QA pipeline using Mistral-7B
â”‚   â”œâ”€â”€ prompts.py                  # Prompt templates
â”‚   â”œâ”€â”€ test_qa_chain_openai.py     # Test with OpenAI chain
â”‚   â”œâ”€â”€ test_qa_chain_mistral.py    # âœ… Test with Mistral chain
â”‚   â”œâ”€â”€ test_mistralai.py           # Standalone generation test
â”‚   â”œâ”€â”€ eval.py                     # Evaluation placeholder
â”‚   â””â”€â”€ utils.py                    # Helpers for chunking, cleaning
â”‚   â””â”€â”€ gradio_ui_llama.py         # Gradio UI interface (planned)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ CUAD_v1/
â”‚           â”œâ”€â”€ master_clauses.csv
â”‚           â”œâ”€â”€ *.txt                         # 498 contract documents
â”‚           â”œâ”€â”€ test_cuad_v1_data.py          # Test doc-CSV consistency
â”‚           â”œâ”€â”€ diagnose_missing_txt.py       # Analyze missing file mappings
â”‚           â””â”€â”€ analyze_data.py               # Understand JSON structure
â”‚
â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ eval_pipeline.py           # Accuracy and coverage scoring (planned)
â”‚   â””â”€â”€ eval_data.csv              # Placeholder for manual Q&A evaluation
â”‚
â”œâ”€â”€ vector_store/
â”‚   â””â”€â”€ chroma.db/                 # Persisted vector DB for fast retrieval
â”‚
â”œâ”€â”€ llamaenv/                      # Python virtual environment
â”œâ”€â”€ vectorstore/                   # Chroma DB directory
â”œâ”€â”€ llmragenv/                     # Python venv (exclude in Git)
â”œâ”€â”€ README.md
â”œâ”€â”€ progress.md                    # ðŸ“ˆ Task and milestone log
â””â”€â”€ requirements.txt

```
------------------------------------------
## ðŸ“Œ What Each Part Does
### âœ… Ingestion
ingest.py:
- Loads CUAD contracts (text + clause metadata)
- hunks them
- Embeds chunks with bge-base-en-v1.5
- Saves them in Chroma vector store

### âœ… RAG Pipeline
retriever.py:
- Loads Chroma DB
- Uses embedding model to find relevant chunks
- qa_chain.py / qa_chain_mistral.py:
- Constructs LangChain RetrievalQA with:

Retriever
- LLM (OpenAI or Mistral)
- Prompt from prompts.py
- prompts.py:
- Stores prompt templates (question answering, summarization, etc.)

### âœ… Test Harness
test_qa_chain_openai.py: test OpenAI QA
test_qa_chain_mistral.py: ðŸ” test QA with Mistral
test_mistralai.py: raw Mistral output (already tested âœ…)

### ðŸ”„ Evaluation (Placeholder)
eval.py: placeholder to measure:
- Precision/Recall/F1 if clause detection is supervised
- Human-in-the-loop validation for QA correctness
---
------------------------------------------
## âœ… Progress Summary

### ðŸ”¸ Dataset Setup
- Downloaded CUAD dataset from Zenodo
- Verified 498 out of 510 documents had corresponding `.txt` files
- Diagnosed and fixed file name mismatches

### ðŸ”¸ Vector Store Creation
- Loaded documents via `ingest.py`
- Chunked into 73,706 segments using LangChain
- Used `sentence-transformers` (BAAI/bge-base-en-v1.5) for embeddings
- Stored into `Chroma` vector DB

### ðŸ”¸ RAG Pipeline (LLaMA version)
- Created `qa_chain_llama.py` with `RetrievalQA` from LangChain
- Tested local responses using `test_qa_chain_llama.py`

### ðŸ”¸ Model Testing
- Got approved for Hugging Face gated model: `meta-llama/Meta-Llama-Guard-2-8B`
- Logged in via `huggingface-cli login`
- Loaded the model using `transformers` with `bitsandbytes` (8-bit quantization)
- Verified token access and download via `test_llama_guard.py`

### ðŸ”¸ Issues Handled
- Filtered malformed JSON structure in earlier CUAD JSON file
- Converted to using CSV+TXT from CUAD v1 instead
- Addressed Chroma metadata errors by sanitizing field types
- Avoided re-ingestion by reusing same embeddings across variants

---
------------------------------------------
## ðŸ’» Setup Instructions

### ðŸ”§ 1. Create and activate environment
```bash
python3 -m venv llamaenv
source llamaenv/bin/activate
```

### ðŸ“¦ 2. Install dependencies
```bash
pip install torch transformers accelerate bitsandbytes
pip install sentence-transformers chromadb
pip install langchain langchain-community
```

### ðŸ—‚ 3. Prepare CUAD data
- Download CUAD v1 ZIP from: https://zenodo.org/record/4595762
- Unzip to: `data/raw/CUAD_v1/`

---

## ðŸš€ Running the Project

### ðŸ“¥ Embed Documents
```bash
python app/ingest.py
```

### ðŸ§  Test LLaMA Model Standalone
```bash
python app/test_llama_guard.py
```

### ðŸ” Test RAG Pipeline
```bash
python app/test_qa_chain_llama.py
```

------------------------------------------

## ðŸš€ Quickstart

### 1. ðŸ“¦ Install

```bash
python3 -m venv llmragenv
source llmragenv/bin/activate

pip install -r requirements.txt
```

> Ensure you have CUDA + bitsandbytes dependencies installed for GPU support.

---

### 2. ðŸ“„ Prepare Data

- Download CUAD v1 from [Zenodo](https://zenodo.org/record/4592955) or GitHub.
- Place `master_clauses.csv` and `.txt` files into `data/raw/CUAD_v1/`.

---

### 3. ðŸ”Œ Ingest Documents

```bash
python app/ingest.py
```

- This will:
  - Load and chunk contracts
  - Embed them
  - Store in `Chroma` vector DB

---

### 4. ðŸ§ª Test the Model

#### âœ… Test local Mistral model:

```bash
python app/test_mistralai.py
```

#### âœ… Test full QA chain (retriever + Mistral):

```bash
python app/test_qa_chain_mistral.py
```

------------------------------------------

## ðŸ”® Upcoming Work

- âœ… Restore modular `retriever.py` and `prompts.py`
- ðŸ”„ Add `main_llama.py` FastAPI backend
- ðŸ’¬ Add `gradio_ui_llama.py` for interactive UI
- ðŸ“Š Add `eval_pipeline.py` for clause matching evaluation
- ðŸ“¦ Add `requirements.txt` for reproducibility

---

## ðŸ™Œ Contributions & Extensions

This scaffold can be extended for:
- Clause classification or summarization
- Fine-tuning on downstream legal tasks
- Model comparison (OpenAI vs LLaMA vs Mistral)
- UI deployment (Streamlit, Gradio, web frontend)

