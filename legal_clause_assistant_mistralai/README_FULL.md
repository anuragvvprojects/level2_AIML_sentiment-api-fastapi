# ğŸ§  Legal Clause Assistant (Local RAG using Meta-Llama-Guard-2-8B)

This is a complete Retrieval-Augmented Generation (RAG) project to assist with legal clause understanding, powered by **Meta-Llama-Guard-2-8B** running locally using `transformers` + `bitsandbytes`.

It uses the CUAD dataset to retrieve relevant legal contract segments and generate contextual answers.

---

## ğŸ“‚ Project Structure

```
legal_clause_assistant_llama3/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ingest.py                  # Load, chunk, and embed CUAD documents into Chroma DB
â”‚   â”œâ”€â”€ retriever.py               # Handles retrieval from the vector store
â”‚   â”œâ”€â”€ prompts.py                 # Prompt templates for the LLM
â”‚   â”œâ”€â”€ qa_chain_llama.py          # RAG chain using local Meta-Llama model
â”‚   â”œâ”€â”€ test_qa_chain_llama.py     # Test script for full RAG pipeline
â”‚   â”œâ”€â”€ test_llama_guard.py        # Standalone model loading and response test
â”‚   â”œâ”€â”€ main_llama.py              # FastAPI backend (planned)
â”‚   â””â”€â”€ gradio_ui_llama.py         # Gradio UI interface (planned)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ CUAD_v1/
â”‚           â”œâ”€â”€ master_clauses.csv
â”‚           â”œâ”€â”€ *.txt                         # 498 contract documents
â”‚           â”œâ”€â”€ test_cuad_v1_data.py          # Test doc-CSV consistency
â”‚           â”œâ”€â”€ diagnose_missing_txt.py       # Analyze missing file mappings
â”‚           â””â”€â”€ analyze_data.py               # Understand JSON structure
â”‚
â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ eval_pipeline.py           # Accuracy and coverage scoring (planned)
â”‚   â””â”€â”€ eval_data.csv              # Placeholder for manual Q&A evaluation
â”‚
â”œâ”€â”€ vector_store/
â”‚   â””â”€â”€ chroma.db/                 # Persisted vector DB for fast retrieval
â”‚
â”œâ”€â”€ llamaenv/                      # Python virtual environment
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt (planned)
```

---

## âœ… Progress Summary

### ğŸ”¸ Dataset Setup
- Downloaded CUAD dataset from Zenodo
- Verified 498 out of 510 documents had corresponding `.txt` files
- Diagnosed and fixed file name mismatches

### ğŸ”¸ Vector Store Creation
- Loaded documents via `ingest.py`
- Chunked into 73,706 segments using LangChain
- Used `sentence-transformers` (BAAI/bge-base-en-v1.5) for embeddings
- Stored into `Chroma` vector DB

### ğŸ”¸ RAG Pipeline (LLaMA version)
- Created `qa_chain_llama.py` with `RetrievalQA` from LangChain
- Tested local responses using `test_qa_chain_llama.py`

### ğŸ”¸ Model Testing
- Got approved for Hugging Face gated model: `meta-llama/Meta-Llama-Guard-2-8B`
- Logged in via `huggingface-cli login`
- Loaded the model using `transformers` with `bitsandbytes` (8-bit quantization)
- Verified token access and download via `test_llama_guard.py`

### ğŸ”¸ Issues Handled
- Filtered malformed JSON structure in earlier CUAD JSON file
- Converted to using CSV+TXT from CUAD v1 instead
- Addressed Chroma metadata errors by sanitizing field types
- Avoided re-ingestion by reusing same embeddings across variants

---

## ğŸ’» Setup Instructions

### ğŸ”§ 1. Create and activate environment
```bash
python3 -m venv llamaenv
source llamaenv/bin/activate
```

### ğŸ“¦ 2. Install dependencies
```bash
pip install torch transformers accelerate bitsandbytes
pip install sentence-transformers chromadb
pip install langchain langchain-community
```

### ğŸ—‚ 3. Prepare CUAD data
- Download CUAD v1 ZIP from: https://zenodo.org/record/4595762
- Unzip to: `data/raw/CUAD_v1/`

---

## ğŸš€ Running the Project

### ğŸ“¥ Embed Documents
```bash
python app/ingest.py
```

### ğŸ§  Test LLaMA Model Standalone
```bash
python app/test_llama_guard.py
```

### ğŸ” Test RAG Pipeline
```bash
python app/test_qa_chain_llama.py
```

---

## ğŸ”® Upcoming Work

- âœ… Restore modular `retriever.py` and `prompts.py`
- ğŸ”„ Add `main_llama.py` FastAPI backend
- ğŸ’¬ Add `gradio_ui_llama.py` for interactive UI
- ğŸ“Š Add `eval_pipeline.py` for clause matching evaluation
- ğŸ“¦ Add `requirements.txt` for reproducibility

---

## ğŸ™Œ Contributions & Extensions

This scaffold can be extended for:
- Clause classification or summarization
- Fine-tuning on downstream legal tasks
- Model comparison (OpenAI vs LLaMA vs Mistral)
- UI deployment (Streamlit, Gradio, web frontend)

